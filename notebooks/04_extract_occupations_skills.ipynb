{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34bb6847",
   "metadata": {},
   "source": [
    "# Extract Occupations and Skills from PAD Chunks\n",
    "\n",
    "Extract occupations and skills from markdown chunks using OpenAI custom GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0438565",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "d5fc2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Import our config\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.config import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656b3a0",
   "metadata": {},
   "source": [
    "## 2. Load Configuration and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0a626195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment variables loaded\n",
      "  API Key: sk-proj-cj...__0A\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "project_root = Path.cwd().parent\n",
    "env_path = project_root / \".env\"\n",
    "\n",
    "if not env_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"'.env' file not found at {env_path}\\n\"\n",
    "        \"Please copy .env.example to .env and add your OpenAI API key.\"\n",
    "    )\n",
    "\n",
    "# Load from specific path\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Load project config\n",
    "config = load_config()\n",
    "\n",
    "# Get OpenAI API key from environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing required environment variable: OPENAI_API_KEY\")\n",
    "\n",
    "print(\"✓ Environment variables loaded\")\n",
    "print(f\"  API Key: {OPENAI_API_KEY[:10]}...{OPENAI_API_KEY[-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc91d3d",
   "metadata": {},
   "source": [
    "## 3. Set Up Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9a619860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks directory: /Users/lauren/repos/PAD2Skills/data/silver/pads_md_chunks\n",
      "Output directory: /Users/lauren/repos/PAD2Skills/data/silver/occupations_skills_json\n",
      "Chunks exist: True\n"
     ]
    }
   ],
   "source": [
    "# Get paths\n",
    "md_dir = project_root / config.paths.markdown\n",
    "chunks_dir = md_dir.parent / \"pads_md_chunks\"\n",
    "output_dir = project_root / \"data\" / \"silver\" / \"occupations_skills_json\"\n",
    "\n",
    "# Create output directory\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Chunks directory: {chunks_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Chunks exist: {chunks_dir.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158bd4da",
   "metadata": {},
   "source": [
    "## 4. Load Chunk Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "20acf53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 chunk files\n",
      "\n",
      "First 5 chunks:\n",
      "  P075941_0_strategic_context.md                                30.30 KB\n",
      "  P075941_10_economic_and_financial_analysis_implementation_arrangements.md 185.08 KB\n",
      "  P075941_11_power_supply_options_for_the_nile_equatorial_lakes_region_nel.md  10.44 KB\n",
      "  P075941_12_summary_of_the_power_sectors_in_burundi_rwanda_and_tanzania.md  32.54 KB\n",
      "  P075941_13_implementation_support_team.md                      5.18 KB\n",
      "  ... and 11 more\n"
     ]
    }
   ],
   "source": [
    "# Find all markdown chunk files\n",
    "chunk_files = sorted(chunks_dir.glob(\"*.md\"))\n",
    "\n",
    "print(f\"Found {len(chunk_files)} chunk files\")\n",
    "print(\"\\nFirst 5 chunks:\")\n",
    "for chunk_file in chunk_files[:5]:\n",
    "    size_kb = chunk_file.stat().st_size / 1024\n",
    "    print(f\"  {chunk_file.name:60s} {size_kb:6.2f} KB\")\n",
    "\n",
    "if len(chunk_files) > 5:\n",
    "    print(f\"  ... and {len(chunk_files) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef26157",
   "metadata": {},
   "source": [
    "## 5. Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "179a7b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"✓ OpenAI client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0782ca9",
   "metadata": {},
   "source": [
    "## 6. Load Abbreviations File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "686905be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded abbreviations file: P075941_abbr.md\n",
      "  Size: 4506 chars\n",
      "  Preview:\n",
      "Abbreviation | Definition\n",
      "--- | ---\n",
      "AfDB | Africa Development Bank\n",
      "BoQ | Bill of Quantities\n",
      "CAG | Controller and Auditor General\n",
      "CAS | Country Assistance Strategy\n",
      "CBWS | Comprehensive Basin-wide Study...\n"
     ]
    }
   ],
   "source": [
    "# Determine project_id from first chunk file\n",
    "if chunk_files:\n",
    "    first_chunk = chunk_files[0]\n",
    "    project_id = first_chunk.stem.split('_', 1)[0]\n",
    "    \n",
    "    # Load abbreviations file for this project\n",
    "    abbr_dir = project_root / \"data\" / \"silver\" / \"abbreviations_md\"\n",
    "    abbr_file = abbr_dir / f\"{project_id}_abbr.md\"\n",
    "    \n",
    "    if abbr_file.exists():\n",
    "        abbreviations_text = abbr_file.read_text(encoding='utf-8')\n",
    "        print(f\"✓ Loaded abbreviations file: {abbr_file.name}\")\n",
    "        print(f\"  Size: {len(abbreviations_text)} chars\")\n",
    "        print(f\"  Preview:\\n{abbreviations_text[:200]}...\")\n",
    "    else:\n",
    "        abbreviations_text = \"\"\n",
    "        print(f\"⚠ No abbreviations file found: {abbr_file}\")\n",
    "        print(\"  Proceeding without abbreviations context\")\n",
    "else:\n",
    "    abbreviations_text = \"\"\n",
    "    print(\"⚠ No chunk files found\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545e4e7",
   "metadata": {},
   "source": [
    "## 7. Process Each Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2847ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16 chunks...\n",
      "\n",
      "[1/16] Processing: P075941_0_strategic_context.md\n",
      "  Project ID: P075941, Section ID: 0\n",
      "  Chunk size: 31030 chars\n",
      "  With abbreviations: 35538 chars\n",
      "  ✓ Saved to: P075941_0_occupations.json\n",
      "\n",
      "[2/16] Processing: P075941_10_economic_and_financial_analysis_implementation_arrangements.md\n",
      "  Project ID: P075941, Section ID: 10\n",
      "  Chunk size: 189523 chars\n",
      "  With abbreviations: 194031 chars\n",
      "  ✓ Saved to: P075941_10_occupations.json\n",
      "\n",
      "[3/16] Processing: P075941_11_power_supply_options_for_the_nile_equatorial_lakes_region_nel.md\n",
      "  Project ID: P075941, Section ID: 11\n",
      "  Chunk size: 10695 chars\n",
      "  With abbreviations: 15203 chars\n",
      "  ✓ Saved to: P075941_11_occupations.json\n",
      "\n",
      "[4/16] Processing: P075941_12_summary_of_the_power_sectors_in_burundi_rwanda_and_tanzania.md\n",
      "  Project ID: P075941, Section ID: 12\n",
      "  Chunk size: 33321 chars\n",
      "  With abbreviations: 37829 chars\n",
      "  ✓ Saved to: P075941_12_occupations.json\n",
      "\n",
      "[5/16] Processing: P075941_13_implementation_support_team.md\n",
      "  Project ID: P075941, Section ID: 13\n",
      "  Chunk size: 5300 chars\n",
      "  With abbreviations: 9808 chars\n",
      "  ✓ Saved to: P075941_13_occupations.json\n",
      "\n",
      "[6/16] Processing: P075941_14_communication_strategy.md\n",
      "  Project ID: P075941, Section ID: 14\n",
      "  Chunk size: 16920 chars\n",
      "  With abbreviations: 21428 chars\n",
      "  ✓ Saved to: P075941_14_occupations.json\n",
      "\n",
      "[7/16] Processing: P075941_15_documents_in_the_project_file.md\n",
      "  Project ID: P075941, Section ID: 15\n",
      "  Chunk size: 4707 chars\n",
      "  With abbreviations: 9215 chars\n",
      "  ✓ Saved to: P075941_15_occupations.json\n",
      "\n",
      "[8/16] Processing: P075941_1_project_development_objectives.md\n",
      "  Project ID: P075941, Section ID: 1\n",
      "  Chunk size: 2769 chars\n",
      "  With abbreviations: 7277 chars\n",
      "  ✓ Saved to: P075941_1_occupations.json\n",
      "\n",
      "[9/16] Processing: P075941_2_project_description.md\n",
      "  Project ID: P075941, Section ID: 2\n",
      "  Chunk size: 17649 chars\n",
      "  With abbreviations: 22157 chars\n",
      "  ✓ Saved to: P075941_2_occupations.json\n",
      "\n",
      "[10/16] Processing: P075941_3_implementation.md\n",
      "  Project ID: P075941, Section ID: 3\n",
      "  Chunk size: 8975 chars\n",
      "  With abbreviations: 13483 chars\n",
      "  ✓ Saved to: P075941_3_occupations.json\n",
      "\n",
      "[11/16] Processing: P075941_4_key_risks_and_mitigation_measures.md\n",
      "  Project ID: P075941, Section ID: 4\n",
      "  Chunk size: 10570 chars\n",
      "  With abbreviations: 15078 chars\n",
      "  ✓ Saved to: P075941_4_occupations.json\n",
      "\n",
      "[12/16] Processing: P075941_5_appraisal_summary.md\n",
      "  Project ID: P075941, Section ID: 5\n",
      "  Chunk size: 48636 chars\n",
      "  With abbreviations: 53144 chars\n",
      "  ✓ Saved to: P075941_5_occupations.json\n",
      "\n",
      "[13/16] Processing: P075941_6_results_framework_and_monitoring.md\n",
      "  Project ID: P075941, Section ID: 6\n",
      "  Chunk size: 15964 chars\n",
      "  With abbreviations: 20472 chars\n",
      "  ✓ Saved to: P075941_6_occupations.json\n",
      "\n",
      "[14/16] Processing: P075941_7_detailed_project_description.md\n",
      "  Project ID: P075941, Section ID: 7\n",
      "  Chunk size: 22009 chars\n",
      "  With abbreviations: 26517 chars\n",
      "  ✓ Saved to: P075941_7_occupations.json\n",
      "\n",
      "[15/16] Processing: P075941_8_implementation_arrangements_regional_rusumo_falls_hydroelectric_project.md\n",
      "  Project ID: P075941, Section ID: 8\n",
      "  Chunk size: 101151 chars\n",
      "  With abbreviations: 105659 chars\n",
      "  ✓ Saved to: P075941_8_occupations.json\n",
      "\n",
      "[16/16] Processing: P075941_9_operational_risk_assessment_framework_oraf.md\n",
      "  Project ID: P075941, Section ID: 9\n",
      "  Chunk size: 116773 chars\n",
      "  With abbreviations: 121281 chars\n",
      "  ✓ Saved to: P075941_9_occupations.json\n",
      "\n",
      "================================================================================\n",
      "✓ Processed 16 chunks\n",
      "✓ Results saved to: /Users/lauren/repos/PAD2Skills/data/silver/occupations_skills_json\n"
     ]
    }
   ],
   "source": [
    "print(f\"Processing {len(chunk_files)} chunks...\")\n",
    "print()\n",
    "\n",
    "processed_chunks = []\n",
    "\n",
    "for i, chunk_file in enumerate(chunk_files, 1):\n",
    "    # Parse filename: {project_id}_{section_id}_{snake_title}.md\n",
    "    filename_parts = chunk_file.stem.split('_', 2)\n",
    "    project_id = filename_parts[0]\n",
    "    section_id = filename_parts[1]\n",
    "    \n",
    "    # Read chunk content\n",
    "    chunk_text = chunk_file.read_text(encoding='utf-8')\n",
    "    \n",
    "    # Prepend abbreviations if available\n",
    "    if abbreviations_text:\n",
    "        chunk_text_with_context = abbreviations_text + \"\\n\\n\" + chunk_text\n",
    "    else:\n",
    "        chunk_text_with_context = chunk_text\n",
    "    \n",
    "    print(f\"[{i}/{len(chunk_files)}] Processing: {chunk_file.name}\")\n",
    "    print(f\"  Project ID: {project_id}, Section ID: {section_id}\")\n",
    "    print(f\"  Chunk size: {len(chunk_text)} chars\")\n",
    "    if abbreviations_text:\n",
    "        print(f\"  With abbreviations: {len(chunk_text_with_context)} chars\")\n",
    "    \n",
    "    # Prepare input for custom GPT\n",
    "    input_message = f\"project_id: {project_id}\\nsection_id: {section_id}\\nchunk_text: {chunk_text_with_context}\"\n",
    "    \n",
    "    # Call custom GPT with prompt ID\n",
    "    response = client.responses.create(\n",
    "        prompt={\n",
    "            \"id\": \"pmpt_6950c224bab0819486a7f38e0ae0109b08192593c3d4b4af\",\n",
    "            \"version\": \"15\"\n",
    "        },\n",
    "        input=[\n",
    "            {\"role\": \"user\", \"content\": input_message}\n",
    "        ],\n",
    "        reasoning={\n",
    "            \"summary\": None\n",
    "        },\n",
    "        store=False,\n",
    "        include=[\n",
    "            \"reasoning.encrypted_content\",\n",
    "            \"web_search_call.action.sources\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Extract the text from the response\n",
    "    result = None\n",
    "    for item in response.output:\n",
    "        if hasattr(item, 'content') and hasattr(item, 'role'):\n",
    "            result = item.content[0].text\n",
    "            break\n",
    "    \n",
    "    # Save result to file\n",
    "    output_file = output_dir / f\"{project_id}_{section_id}_occupations.json\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(result)\n",
    "    \n",
    "    processed_chunks.append({\n",
    "        'chunk_file': chunk_file.name,\n",
    "        'project_id': project_id,\n",
    "        'section_id': section_id,\n",
    "        'output_file': output_file.name,\n",
    "        'response_id': response.id\n",
    "    })\n",
    "    \n",
    "    print(f\"  ✓ Saved to: {output_file.name}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"✓ Processed {len(processed_chunks)} chunks\")\n",
    "print(f\"✓ Results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b6e20",
   "metadata": {},
   "source": [
    "## 8. Verify Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "07276056",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 16 output files:\n",
      "================================================================================\n",
      "  P075941_0_occupations.json                                     2.70 KB\n",
      "  P075941_10_occupations.json                                    6.29 KB\n",
      "  P075941_11_occupations.json                                    3.27 KB\n",
      "  P075941_12_occupations.json                                    4.57 KB\n",
      "  P075941_13_occupations.json                                   10.48 KB\n",
      "  P075941_14_occupations.json                                    5.85 KB\n",
      "  P075941_15_occupations.json                                    0.07 KB\n",
      "  P075941_1_occupations.json                                     5.29 KB\n",
      "  P075941_2_occupations.json                                    16.42 KB\n",
      "  P075941_3_occupations.json                                     7.81 KB\n",
      "  ... and 6 more\n",
      "================================================================================\n",
      "Total output files: 16\n"
     ]
    }
   ],
   "source": [
    "# List all output files\n",
    "output_files = sorted(output_dir.glob(\"*_occupations.json\"))\n",
    "\n",
    "print(f\"Created {len(output_files)} output files:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for output_file in output_files[:10]:  # Show first 10\n",
    "    size_kb = output_file.stat().st_size / 1024\n",
    "    print(f\"  {output_file.name:60s} {size_kb:6.2f} KB\")\n",
    "\n",
    "if len(output_files) > 10:\n",
    "    print(f\"  ... and {len(output_files) - 10} more\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total output files: {len(output_files)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAD2Skills",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
