{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b407ebda",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3008c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Import our config\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.config import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bdb4cd",
   "metadata": {},
   "source": [
    "## 2. Load Configuration and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "fbe18082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment variables loaded\n",
      "  API Key: sk-proj-cj...__0A\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "project_root = Path.cwd().parent\n",
    "env_path = project_root / \".env\"\n",
    "\n",
    "if not env_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"'.env' file not found at {env_path}\\n\"\n",
    "        \"Please copy .env.example to .env and add your OpenAI API key.\"\n",
    "    )\n",
    "\n",
    "# Load from specific path\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Load project config\n",
    "config = load_config()\n",
    "\n",
    "# Get OpenAI API key from environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing required environment variable: OPENAI_API_KEY\")\n",
    "\n",
    "print(\"✓ Environment variables loaded\")\n",
    "print(f\"  API Key: {OPENAI_API_KEY[:10]}...{OPENAI_API_KEY[-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309c671",
   "metadata": {},
   "source": [
    "## 3. Set Up Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "fd5262cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown directory: /Users/lauren/repos/PAD2Skills/data/silver/pads_md\n",
      "Prompts directory: /Users/lauren/repos/PAD2Skills/prompts\n",
      "Target file: /Users/lauren/repos/PAD2Skills/data/silver/pads_md/P075941_1.md\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "# Get paths\n",
    "md_dir = project_root / config.paths.markdown\n",
    "prompts_dir = project_root / \"prompts\"\n",
    "\n",
    "# Target markdown file\n",
    "target_file = md_dir / \"P075941_1.md\"\n",
    "project_id = \"P075941\"\n",
    "\n",
    "print(f\"Markdown directory: {md_dir}\")\n",
    "print(f\"Prompts directory: {prompts_dir}\")\n",
    "print(f\"Target file: {target_file}\")\n",
    "print(f\"File exists: {target_file.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5f84a",
   "metadata": {},
   "source": [
    "## 4. Load Markdown Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "78135e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Markdown content loaded (736923 chars)\n",
      "Input message length: 736944 chars\n",
      "\n",
      "Markdown preview (first 500 chars):\n",
      "============================================================\n",
      "Public Disclosure Authorized\n",
      "\n",
      "Public Disclosure Authorized\n",
      "\n",
      "Public Disclosure Authorized Public Disclosure Authorized\n",
      "\n",
      "Public Disclosure Authorized\n",
      "\n",
      "Public Disclosure Authorized\n",
      "\n",
      "Document of The World Bank\n",
      "\n",
      "## FOR OFFICIAL USE ONLY\n",
      "\n",
      "## INTERNATIONAL DEVELOPMENT ASSOCIATION\n",
      "\n",
      "## PROJECT APPRAISAL DOCUMENT\n",
      "\n",
      "ON  A PROPOSED CREDIT IN THE AMOUNT OF  SDR 37.80  MILLION (US$56.65 MILLION EQUIVALENT) AND A PROPOSED GRANT IN THE AMOUNT OF SDR 37.80 MILLION (US$ 56.65 MILLION EQUIVALENT) TO  THE  REPUBLIC \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Load markdown file\n",
    "if not target_file.exists():\n",
    "    raise FileNotFoundError(f\"Markdown file not found: {target_file}\")\n",
    "\n",
    "markdown_content = target_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# Prepare input message for custom GPT\n",
    "input_message = f\"Project ID: {project_id}\\n\\n{markdown_content}\"\n",
    "\n",
    "print(f\"✓ Markdown content loaded ({len(markdown_content)} chars)\")\n",
    "print(f\"Input message length: {len(input_message)} chars\")\n",
    "print(f\"\\nMarkdown preview (first 500 chars):\")\n",
    "print(\"=\" * 60)\n",
    "print(markdown_content[:500])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03c448f",
   "metadata": {},
   "source": [
    "## 5. Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fc335225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"✓ OpenAI client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f42c1",
   "metadata": {},
   "source": [
    "## 6. Send Request to Identify Document Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85e00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request to custom GPT...\n",
      "Input length: 736944 chars\n",
      "\n",
      "✓ Response received\n",
      "  Response ID: resp_0731195c302b01bb006951bbf10bdc8196ab439d52324f7d54\n",
      "  Status: completed\n"
     ]
    }
   ],
   "source": [
    "print(\"Sending request to custom GPT...\")\n",
    "print(f\"Input length: {len(input_message)} chars\")\n",
    "print()\n",
    "\n",
    "# Call custom GPT with prompt ID\n",
    "response = client.responses.create(\n",
    "    prompt={\n",
    "        \"id\": \"pmpt_6950b4992fcc8194b89fc2d87be08bf8088afcd3c3f3a4d7\",\n",
    "        \"version\": \"6\"\n",
    "    },\n",
    "    input=[\n",
    "        {\"role\": \"user\", \"content\": input_message}\n",
    "    ],\n",
    "    reasoning={\n",
    "        \"summary\": \"auto\"\n",
    "    },\n",
    "    store=True,\n",
    "    include=[\n",
    "        \"reasoning.encrypted_content\",\n",
    "        \"web_search_call.action.sources\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e2510dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Response received\n",
      "  Response ID: resp_0731195c302b01bb006951bbf10bdc8196ab439d52324f7d54\n",
      "  Status: completed\n"
     ]
    }
   ],
   "source": [
    "# Extract the text from the response\n",
    "# response.output is a list: [ResponseReasoningItem, ResponseOutputMessage]\n",
    "# The message content is in output[1].content[0].text\n",
    "for item in response.output:\n",
    "    if hasattr(item, 'content') and hasattr(item, 'role'):\n",
    "        result = item.content[0].text\n",
    "        break\n",
    "\n",
    "print(\"✓ Response received\")\n",
    "print(f\"  Response ID: {response.id}\")\n",
    "print(f\"  Status: {response.status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c67da19",
   "metadata": {},
   "source": [
    "## 7. Save Results to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "f65e4b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved sections to: /Users/lauren/repos/PAD2Skills/data/silver/document_sections/P075941_sections.json\n",
      "  File size: 2.73 KB\n"
     ]
    }
   ],
   "source": [
    "# Save result directly to JSON file\n",
    "output_dir = project_root / \"data\" / \"silver\" / \"document_sections\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = output_dir / f\"{project_id}_sections.json\"\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(result)\n",
    "\n",
    "print(f\"✓ Saved sections to: {output_file}\")\n",
    "print(f\"  File size: {output_file.stat().st_size / 1024:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9a125",
   "metadata": {},
   "source": [
    "## 8. Read and Parse Section JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "d00bf5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 16 sections\n",
      "  0: STRATEGIC CONTEXT\n",
      "  1: PROJECT DEVELOPMENT OBJECTIVES\n",
      "  2: PROJECT DESCRIPTION\n",
      "  3: IMPLEMENTATION\n",
      "  4: KEY RISKS AND MITIGATION MEASURES\n",
      "  ... and 11 more\n"
     ]
    }
   ],
   "source": [
    "# Read and parse the sections JSON file\n",
    "with open(output_file, 'r', encoding='utf-8') as f:\n",
    "    sections_data = json.load(f)\n",
    "\n",
    "sections = sections_data['sections']\n",
    "\n",
    "print(f\"✓ Loaded {len(sections)} sections\")\n",
    "for section in sections[:5]:  # Show first 5\n",
    "    print(f\"  {section['section_id']}: {section['section_title']}\")\n",
    "if len(sections) > 5:\n",
    "    print(f\"  ... and {len(sections) - 5} more\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f1b6b",
   "metadata": {},
   "source": [
    "## 9. Split Markdown into Section Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "1b9c9761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting markdown into 16 section chunks...\n",
      "Output directory: /Users/lauren/repos/PAD2Skills/data/silver/pads_md_chunks\n",
      "\n",
      "✓ Saved: P075941_0_strategic_context.md (31030 chars)\n",
      "✓ Saved: P075941_1_project_development_objectives.md (2769 chars)\n",
      "✓ Saved: P075941_2_project_description.md (17649 chars)\n",
      "✓ Saved: P075941_3_implementation.md (8975 chars)\n",
      "✓ Saved: P075941_4_key_risks_and_mitigation_measures.md (10570 chars)\n",
      "✓ Saved: P075941_5_appraisal_summary.md (48636 chars)\n",
      "✓ Saved: P075941_6_results_framework_and_monitoring.md (15964 chars)\n",
      "✓ Saved: P075941_7_detailed_project_description.md (22009 chars)\n",
      "✓ Saved: P075941_8_implementation_arrangements_regional_rusumo_falls_hydroelectric_project.md (101151 chars)\n",
      "✓ Saved: P075941_9_operational_risk_assessment_framework_oraf.md (116773 chars)\n",
      "✓ Saved: P075941_10_economic_and_financial_analysis_implementation_arrangements.md (189523 chars)\n",
      "✓ Saved: P075941_11_power_supply_options_for_the_nile_equatorial_lakes_region_nel.md (10695 chars)\n",
      "✓ Saved: P075941_12_summary_of_the_power_sectors_in_burundi_rwanda_and_tanzania.md (33321 chars)\n",
      "✓ Saved: P075941_13_implementation_support_team.md (5300 chars)\n",
      "✓ Saved: P075941_14_communication_strategy.md (16920 chars)\n",
      "✓ Saved: P075941_15_documents_in_the_project_file.md (4707 chars)\n",
      "\n",
      "✓ Saved 16 section chunks to /Users/lauren/repos/PAD2Skills/data/silver/pads_md_chunks\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def to_snake_case(text):\n",
    "    \"\"\"Convert text to lower snake case\"\"\"\n",
    "    # Replace spaces and special chars with underscores\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', '_', text)\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    \"\"\"Normalize multiple spaces to single space\"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "def find_header_in_markdown(markdown, header_text):\n",
    "    \"\"\"Find header in markdown, handling whitespace differences\"\"\"\n",
    "    # Try exact match first\n",
    "    pos = markdown.find(header_text)\n",
    "    if pos != -1:\n",
    "        return pos\n",
    "    \n",
    "    # Try with normalized whitespace\n",
    "    normalized_header = normalize_whitespace(header_text)\n",
    "    \n",
    "    # Search using regex to match any amount of whitespace\n",
    "    pattern = re.escape(normalized_header).replace(r'\\ ', r'\\s+')\n",
    "    match = re.search(pattern, markdown)\n",
    "    \n",
    "    if match:\n",
    "        return match.start()\n",
    "    \n",
    "    return -1\n",
    "\n",
    "# Create output directory for chunks\n",
    "chunks_dir = md_dir.parent / \"pads_md_chunks\"\n",
    "chunks_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Splitting markdown into {len(sections)} section chunks...\")\n",
    "print(f\"Output directory: {chunks_dir}\")\n",
    "print()\n",
    "\n",
    "# Split the markdown by sections\n",
    "saved_chunks = []\n",
    "for i, section in enumerate(sections):\n",
    "    header_text = section['header_text']\n",
    "    section_id = section['section_id']\n",
    "    section_title = section['section_title']\n",
    "    \n",
    "    # Find the start position of this section (with fuzzy whitespace matching)\n",
    "    start_pos = find_header_in_markdown(markdown_content, header_text)\n",
    "    \n",
    "    if start_pos == -1:\n",
    "        print(f\"⚠ Warning: Could not find header '{header_text}' in markdown\")\n",
    "        continue\n",
    "    \n",
    "    # Find the end position (start of next section, or end of document)\n",
    "    if i < len(sections) - 1:\n",
    "        next_header = sections[i + 1]['header_text']\n",
    "        end_pos = find_header_in_markdown(markdown_content[start_pos + len(header_text):], next_header)\n",
    "        if end_pos == -1:\n",
    "            end_pos = len(markdown_content)\n",
    "        else:\n",
    "            end_pos = start_pos + len(header_text) + end_pos\n",
    "    else:\n",
    "        end_pos = len(markdown_content)\n",
    "    \n",
    "    # Extract the section content\n",
    "    section_content = markdown_content[start_pos:end_pos].rstrip()\n",
    "    \n",
    "    # Generate filename\n",
    "    snake_title = to_snake_case(section_title)\n",
    "    filename = f\"{project_id}_{section_id}_{snake_title}.md\"\n",
    "    chunk_file = chunks_dir / filename\n",
    "    \n",
    "    # Save the chunk\n",
    "    chunk_file.write_text(section_content, encoding='utf-8')\n",
    "    saved_chunks.append({\n",
    "        'file': filename,\n",
    "        'size': len(section_content),\n",
    "        'title': section_title\n",
    "    })\n",
    "    \n",
    "    print(f\"✓ Saved: {filename} ({len(section_content)} chars)\")\n",
    "\n",
    "print()\n",
    "print(f\"✓ Saved {len(saved_chunks)} section chunks to {chunks_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c63f90",
   "metadata": {},
   "source": [
    "## 10. Verify Chunks Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "347948dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all created chunk files\n",
    "chunk_files = sorted(chunks_dir.glob(f\"{project_id}_*.md\"))\n",
    "\n",
    "print(f\"Created {len(chunk_files)} chunk files:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for chunk_file in chunk_files:\n",
    "    size_kb = chunk_file.stat().st_size / 1024\n",
    "    print(f\"  {chunk_file.name:60s} {size_kb:6.2f} KB\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total chunks: {len(chunk_files)}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAD2Skills",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
