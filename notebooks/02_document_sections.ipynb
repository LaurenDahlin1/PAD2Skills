{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6933be9f",
   "metadata": {},
   "source": [
    "# Extract Document Sections from PAD\n",
    "\n",
    "Identify and extract major document sections from PAD markdown files using OpenAI API.\n",
    "\n",
    "**Note:** The reusable extraction logic has been implemented in `src/extraction/`. Use the CLIs for production:\n",
    "- Extract sections: `uv run python -m src.extraction.cli_sections`\n",
    "- Extract abbreviations: `uv run python -m src.extraction.cli_abbreviations`\n",
    "- Create chunked markdown files: `uv run python -m src.extraction.cli_chunks`\n",
    "\n",
    "This notebook contains the original exploration and can be used for testing individual files."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b407ebda",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f63fa0b4",
   "metadata": {},
   "source": [
    "### 0.01 Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3008c052",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Import our config\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.config import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79bdb4cd",
   "metadata": {},
   "source": [
    "### 0.02 Load Configuration and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbe18082",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment variables loaded\n",
      "  API Key: sk-proj-cj...__0A\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "project_root = Path.cwd().parent\n",
    "env_path = project_root / \".env\"\n",
    "\n",
    "if not env_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"'.env' file not found at {env_path}\\n\"\n",
    "        \"Please copy .env.example to .env and add your OpenAI API key.\"\n",
    "    )\n",
    "\n",
    "# Load from specific path\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Load project config\n",
    "config = load_config()\n",
    "\n",
    "# Get OpenAI API key from environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing required environment variable: OPENAI_API_KEY\")\n",
    "\n",
    "print(\"✓ Environment variables loaded\")\n",
    "print(f\"  API Key: {OPENAI_API_KEY[:10]}...{OPENAI_API_KEY[-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b309c671",
   "metadata": {},
   "source": [
    "### 0.03 Set Up Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fd5262cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown directory: /Users/lauren/repos/PAD2Skills/data/silver/pads_md\n",
      "Prompts directory: /Users/lauren/repos/PAD2Skills/prompts\n",
      "Target file: /Users/lauren/repos/PAD2Skills/data/silver/pads_md/P075941_1.md\n",
      "File exists: True\n"
     ]
    }
   ],
   "source": [
    "# Get paths\n",
    "md_dir = project_root / config.paths.markdown\n",
    "prompts_dir = project_root / \"prompts\"\n",
    "\n",
    "# Target markdown file\n",
    "target_file = md_dir / \"P075941_1.md\"\n",
    "project_id = \"P075941\"\n",
    "\n",
    "print(f\"Markdown directory: {md_dir}\")\n",
    "print(f\"Prompts directory: {prompts_dir}\")\n",
    "print(f\"Target file: {target_file}\")\n",
    "print(f\"File exists: {target_file.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90a5f84a",
   "metadata": {},
   "source": [
    "## 1. Load Markdown Content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "78135e87",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Markdown content loaded (736923 chars)\n",
      "Input message length: 736944 chars\n",
      "\n",
      "Markdown preview (first 500 chars):\n",
      "============================================================\n",
      "Public Disclosure Authorized\n",
      "\n",
      "Public Disclosure Authorized\n",
      "\n",
      "Public Disclosure Authorized Public Disclosure Authorized\n",
      "\n",
      "Public Disclosure Authorized\n",
      "\n",
      "Public Disclosure Authorized\n",
      "\n",
      "Document of The World Bank\n",
      "\n",
      "## FOR OFFICIAL USE ONLY\n",
      "\n",
      "## INTERNATIONAL DEVELOPMENT ASSOCIATION\n",
      "\n",
      "## PROJECT APPRAISAL DOCUMENT\n",
      "\n",
      "ON  A PROPOSED CREDIT IN THE AMOUNT OF  SDR 37.80  MILLION (US$56.65 MILLION EQUIVALENT) AND A PROPOSED GRANT IN THE AMOUNT OF SDR 37.80 MILLION (US$ 56.65 MILLION EQUIVALENT) TO  THE  REPUBLIC \n",
      "...\n"
     ]
    }
   ],
   "source": [
    "# Load markdown file\n",
    "if not target_file.exists():\n",
    "    raise FileNotFoundError(f\"Markdown file not found: {target_file}\")\n",
    "\n",
    "markdown_content = target_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "# Prepare input message for custom GPT\n",
    "input_message = f\"Project ID: {project_id}\\n\\n{markdown_content}\"\n",
    "\n",
    "print(f\"✓ Markdown content loaded ({len(markdown_content)} chars)\")\n",
    "print(f\"Input message length: {len(input_message)} chars\")\n",
    "print(f\"\\nMarkdown preview (first 500 chars):\")\n",
    "print(\"=\" * 60)\n",
    "print(markdown_content[:500])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e03c448f",
   "metadata": {},
   "source": [
    "## 2. Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "fc335225",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"✓ OpenAI client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f42c1",
   "metadata": {},
   "source": [
    "## 3. Send Request to Identify Document Sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85e00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending request to custom GPT...\n",
      "Input length: 736944 chars\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Sending request to custom GPT...\")\n",
    "print(f\"Input length: {len(input_message)} chars\")\n",
    "print()\n",
    "\n",
    "# Call custom GPT with prompt ID\n",
    "response = client.responses.create(\n",
    "    prompt={\n",
    "        \"id\": \"pmpt_6950b4992fcc8194b89fc2d87be08bf8088afcd3c3f3a4d7\",\n",
    "        \"version\": \"6\"\n",
    "    },\n",
    "    input=[\n",
    "        {\"role\": \"user\", \"content\": input_message}\n",
    "    ],\n",
    "    reasoning={\n",
    "        \"summary\": None\n",
    "    },\n",
    "    store=True,\n",
    "    include=[\n",
    "        \"reasoning.encrypted_content\",\n",
    "        \"web_search_call.action.sources\"\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e2510dad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Response received\n",
      "  Response ID: resp_07309278ff531aad0069573f3d960881919e805586cf991eb1\n",
      "  Status: completed\n"
     ]
    }
   ],
   "source": [
    "# Extract the text from the response\n",
    "# response.output is a list: [ResponseReasoningItem, ResponseOutputMessage]\n",
    "# The message content is in output[1].content[0].text\n",
    "for item in response.output:\n",
    "    if hasattr(item, 'content') and hasattr(item, 'role'):\n",
    "        result = item.content[0].text\n",
    "        break\n",
    "\n",
    "print(\"✓ Response received\")\n",
    "print(f\"  Response ID: {response.id}\")\n",
    "print(f\"  Status: {response.status}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c67da19",
   "metadata": {},
   "source": [
    "## 4. Save Results to File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f65e4b42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved sections to: /Users/lauren/repos/PAD2Skills/data/silver/document_sections/P075941_sections.json\n",
      "  File size: 2.73 KB\n"
     ]
    }
   ],
   "source": [
    "# Save result directly to JSON file\n",
    "output_dir = project_root / \"data\" / \"silver\" / \"document_sections\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_file = output_dir / f\"{project_id}_sections.json\"\n",
    "\n",
    "with open(output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(result)\n",
    "\n",
    "print(f\"✓ Saved sections to: {output_file}\")\n",
    "print(f\"  File size: {output_file.stat().st_size / 1024:.2f} KB\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ea9a125",
   "metadata": {},
   "source": [
    "## 5. Read and Parse Section JSON"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d00bf5cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded 16 sections\n",
      "  0: STRATEGIC CONTEXT\n",
      "  1: PROJECT DEVELOPMENT OBJECTIVES\n",
      "  2: PROJECT DESCRIPTION\n",
      "  3: IMPLEMENTATION\n",
      "  4: KEY RISKS AND MITIGATION MEASURES\n",
      "  ... and 11 more\n"
     ]
    }
   ],
   "source": [
    "# Read and parse the sections JSON file\n",
    "with open(output_file, 'r', encoding='utf-8') as f:\n",
    "    sections_data = json.load(f)\n",
    "\n",
    "sections = sections_data['sections']\n",
    "\n",
    "print(f\"✓ Loaded {len(sections)} sections\")\n",
    "for section in sections[:5]:  # Show first 5\n",
    "    print(f\"  {section['section_id']}: {section['section_title']}\")\n",
    "if len(sections) > 5:\n",
    "    print(f\"  ... and {len(sections) - 5} more\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb2f1b6b",
   "metadata": {},
   "source": [
    "## 6. Split Markdown into Section Chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1b9c9761",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting markdown into 16 section chunks...\n",
      "Output directory: /Users/lauren/repos/PAD2Skills/data/silver/pads_md_chunks\n",
      "\n",
      "✓ Saved: P075941_0_strategic_context.md (31030 chars)\n",
      "✓ Saved: P075941_1_project_development_objectives.md (2769 chars)\n",
      "✓ Saved: P075941_2_project_description.md (17649 chars)\n",
      "✓ Saved: P075941_3_implementation.md (8975 chars)\n",
      "✓ Saved: P075941_4_key_risks_and_mitigation_measures.md (10570 chars)\n",
      "✓ Saved: P075941_5_appraisal_summary.md (48636 chars)\n",
      "✓ Saved: P075941_6_results_framework_and_monitoring.md (15964 chars)\n",
      "✓ Saved: P075941_7_detailed_project_description.md (22009 chars)\n",
      "✓ Saved: P075941_8_implementation_arrangements_regional_rusumo_falls_hydroelectric_project.md (101151 chars)\n",
      "✓ Saved: P075941_9_operational_risk_assessment_framework_oraf.md (116773 chars)\n",
      "✓ Saved: P075941_10_economic_and_financial_analysis_implementation_arrangements.md (189523 chars)\n",
      "✓ Saved: P075941_11_power_supply_options_for_the_nile_equatorial_lakes_region_nel.md (10695 chars)\n",
      "✓ Saved: P075941_12_summary_of_the_power_sectors_in_burundi_rwanda_and_tanzania.md (33321 chars)\n",
      "✓ Saved: P075941_13_implementation_support_team.md (5300 chars)\n",
      "✓ Saved: P075941_14_communication_strategy.md (16920 chars)\n",
      "✓ Saved: P075941_15_documents_in_the_project_file.md (4707 chars)\n",
      "\n",
      "✓ Saved 16 section chunks to /Users/lauren/repos/PAD2Skills/data/silver/pads_md_chunks\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "def to_snake_case(text):\n",
    "    \"\"\"Convert text to lower snake case\"\"\"\n",
    "    # Replace spaces and special chars with underscores\n",
    "    text = re.sub(r'[^\\w\\s]', '', text)\n",
    "    text = re.sub(r'\\s+', '_', text)\n",
    "    return text.lower()\n",
    "\n",
    "def normalize_whitespace(text):\n",
    "    \"\"\"Normalize multiple spaces to single space\"\"\"\n",
    "    return re.sub(r'\\s+', ' ', text)\n",
    "\n",
    "def find_header_in_markdown(markdown, header_text):\n",
    "    \"\"\"Find header in markdown, handling whitespace differences\"\"\"\n",
    "    # Try exact match first\n",
    "    pos = markdown.find(header_text)\n",
    "    if pos != -1:\n",
    "        return pos\n",
    "    \n",
    "    # Try with normalized whitespace\n",
    "    normalized_header = normalize_whitespace(header_text)\n",
    "    \n",
    "    # Search using regex to match any amount of whitespace\n",
    "    pattern = re.escape(normalized_header).replace(r'\\ ', r'\\s+')\n",
    "    match = re.search(pattern, markdown)\n",
    "    \n",
    "    if match:\n",
    "        return match.start()\n",
    "    \n",
    "    return -1\n",
    "\n",
    "# Create output directory for chunks\n",
    "chunks_dir = md_dir.parent / \"pads_md_chunks\"\n",
    "chunks_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Splitting markdown into {len(sections)} section chunks...\")\n",
    "print(f\"Output directory: {chunks_dir}\")\n",
    "print()\n",
    "\n",
    "# Split the markdown by sections\n",
    "saved_chunks = []\n",
    "for i, section in enumerate(sections):\n",
    "    header_text = section['header_text']\n",
    "    section_id = section['section_id']\n",
    "    section_title = section['section_title']\n",
    "    \n",
    "    # Find the start position of this section (with fuzzy whitespace matching)\n",
    "    start_pos = find_header_in_markdown(markdown_content, header_text)\n",
    "    \n",
    "    if start_pos == -1:\n",
    "        print(f\"⚠ Warning: Could not find header '{header_text}' in markdown\")\n",
    "        continue\n",
    "    \n",
    "    # Find the end position (start of next section, or end of document)\n",
    "    if i < len(sections) - 1:\n",
    "        next_header = sections[i + 1]['header_text']\n",
    "        end_pos = find_header_in_markdown(markdown_content[start_pos + len(header_text):], next_header)\n",
    "        if end_pos == -1:\n",
    "            end_pos = len(markdown_content)\n",
    "        else:\n",
    "            end_pos = start_pos + len(header_text) + end_pos\n",
    "    else:\n",
    "        end_pos = len(markdown_content)\n",
    "    \n",
    "    # Extract the section content\n",
    "    section_content = markdown_content[start_pos:end_pos].rstrip()\n",
    "    \n",
    "    # Generate filename\n",
    "    snake_title = to_snake_case(section_title)\n",
    "    filename = f\"{project_id}_{section_id}_{snake_title}.md\"\n",
    "    chunk_file = chunks_dir / filename\n",
    "    \n",
    "    # Save the chunk\n",
    "    chunk_file.write_text(section_content, encoding='utf-8')\n",
    "    saved_chunks.append({\n",
    "        'file': filename,\n",
    "        'size': len(section_content),\n",
    "        'title': section_title\n",
    "    })\n",
    "    \n",
    "    print(f\"✓ Saved: {filename} ({len(section_content)} chars)\")\n",
    "\n",
    "print()\n",
    "print(f\"✓ Saved {len(saved_chunks)} section chunks to {chunks_dir}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3c63f90",
   "metadata": {},
   "source": [
    "## 7. Verify Chunks Created"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "347948dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Created 16 chunk files:\n",
      "================================================================================\n",
      "  P075941_0_strategic_context.md                                30.30 KB\n",
      "  P075941_10_economic_and_financial_analysis_implementation_arrangements.md 185.08 KB\n",
      "  P075941_11_power_supply_options_for_the_nile_equatorial_lakes_region_nel.md  10.44 KB\n",
      "  P075941_12_summary_of_the_power_sectors_in_burundi_rwanda_and_tanzania.md  32.54 KB\n",
      "  P075941_13_implementation_support_team.md                      5.18 KB\n",
      "  P075941_14_communication_strategy.md                          16.52 KB\n",
      "  P075941_15_documents_in_the_project_file.md                    4.60 KB\n",
      "  P075941_1_project_development_objectives.md                    2.70 KB\n",
      "  P075941_2_project_description.md                              17.24 KB\n",
      "  P075941_3_implementation.md                                    8.76 KB\n",
      "  P075941_4_key_risks_and_mitigation_measures.md                10.32 KB\n",
      "  P075941_5_appraisal_summary.md                                47.50 KB\n",
      "  P075941_6_results_framework_and_monitoring.md                 15.59 KB\n",
      "  P075941_7_detailed_project_description.md                     21.49 KB\n",
      "  P075941_8_implementation_arrangements_regional_rusumo_falls_hydroelectric_project.md  98.78 KB\n",
      "  P075941_9_operational_risk_assessment_framework_oraf.md      114.04 KB\n",
      "================================================================================\n",
      "Total chunks: 16\n"
     ]
    }
   ],
   "source": [
    "# List all created chunk files\n",
    "chunk_files = sorted(chunks_dir.glob(f\"{project_id}_*.md\"))\n",
    "\n",
    "print(f\"Created {len(chunk_files)} chunk files:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for chunk_file in chunk_files:\n",
    "    size_kb = chunk_file.stat().st_size / 1024\n",
    "    print(f\"  {chunk_file.name:60s} {size_kb:6.2f} KB\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total chunks: {len(chunk_files)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "794dc9d9",
   "metadata": {},
   "source": [
    "## 8. Extract Abbreviations Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3d2a700d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Reloaded markdown content\n",
      "  Length: 736,923 characters\n",
      "  File: P075941_1.md\n"
     ]
    }
   ],
   "source": [
    "# Reload markdown content\n",
    "markdown_content = target_file.read_text(encoding=\"utf-8\")\n",
    "\n",
    "print(f\"✓ Reloaded markdown content\")\n",
    "print(f\"  Length: {len(markdown_content):,} characters\")\n",
    "print(f\"  File: {target_file.name}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12be8c4",
   "metadata": {},
   "source": [
    "### 8.01 Extract Text Up to First Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3872483a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Found first occurrence of 'table' at position 8472\n",
      "  Extracted 8471 characters\n",
      "\n",
      "Extracted text preview (2000-3000 chars):\n",
      "================================================================================\n",
      " Supply  Company  Ltd.\n",
      "\n",
      "DflD\n",
      "\n",
      "Department  for  International Development, UK\n",
      "\n",
      "DP\n",
      "\n",
      "Development  Partner\n",
      "\n",
      "DRC\n",
      "\n",
      "Democratic  Republic of  Congo\n",
      "\n",
      "E&amp;M\n",
      "\n",
      "Electrical and  Mechanical\n",
      "\n",
      "E&amp;S\n",
      "\n",
      "Erosion  and Safety\n",
      "\n",
      "EAPP\n",
      "\n",
      "East  Africa Power  Pool\n",
      "\n",
      "EARP\n",
      "\n",
      "Electricity Access  Roll-out Program\n",
      "\n",
      "EDPRS\n",
      "\n",
      "Economic Development  and  Poverty Reduction  Strategy\n",
      "\n",
      "EIRR\n",
      "\n",
      "Economic Internal Rate  of Return\n",
      "\n",
      "ENSAP\n",
      "\n",
      "Eastern Nile  Subsidiary Action  Program\n",
      "\n",
      "EPC\n",
      "\n",
      "Engineering- Procurement- Construction\n",
      "\n",
      "ESMP\n",
      "\n",
      "Environment  and  Social Management Plan\n",
      "\n",
      "ESMU\n",
      "\n",
      "Environmental and  Social Management Unit\n",
      "\n",
      "EWSA\n",
      "\n",
      "Energy,  Water  and  Sanitation Authority, Rwanda\n",
      "\n",
      "EWURA\n",
      "\n",
      "Energy  and  Water  Utilities Regulatory Authority\n",
      "\n",
      "FBU\n",
      "\n",
      "Burundi  Franc\n",
      "\n",
      "ABER\n",
      "\n",
      "| FDS       | Full  Development  Scheme                                 |\n",
      "|-----------|-----------------------------------------------------------|\n",
      "| FIRR      | Financial  Internal  Rate  of  Return                     |\n",
      "| FMM       | Financial  Management Manual              \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "\n",
    "# Find the first occurrence of \"table\" (case insensitive)\n",
    "match = re.search(r'\\btable\\b', markdown_content, re.IGNORECASE)\n",
    "\n",
    "if match:\n",
    "    # Extract text from beginning up to the first \"table\"\n",
    "    abbreviations_text = markdown_content[:match.start()].strip()\n",
    "    \n",
    "    print(f\"✓ Found first occurrence of 'table' at position {match.start()}\")\n",
    "    print(f\"  Extracted {len(abbreviations_text)} characters\")\n",
    "    print(f\"\\nExtracted text preview (2000-3000 chars):\")\n",
    "    print(\"=\" * 80)\n",
    "    print(abbreviations_text[2000:3000])\n",
    "else:\n",
    "    print(\"✗ No occurrence of 'table' found in markdown content\")\n",
    "    abbreviations_text = \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62ef9ff1",
   "metadata": {},
   "source": [
    "### 8.02 Send to OpenAI API for Table Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "0a02a144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sending abbreviations text to OpenAI API...\n",
      "Input length: 8471 chars\n",
      "\n",
      "✓ Response received\n",
      "  Response ID: resp_039b882a1337aaae0069575232cae4819498db748bf065574e\n",
      "  Status: completed\n",
      "  Table length: 4506 chars\n",
      "\n",
      "Table preview (first 500 chars):\n",
      "================================================================================\n",
      "Abbreviation | Definition\n",
      "--- | ---\n",
      "AfDB | Africa Development Bank\n",
      "BoQ | Bill of Quantities\n",
      "CAG | Controller and Auditor General\n",
      "CAS | Country Assistance Strategy\n",
      "CBWS | Comprehensive Basin-wide Study\n",
      "COD | Commercial Operation Date\n",
      "COMESA | Common Market for Eastern and Southern Africa\n",
      "CSO | Civil Society Organization\n",
      "DARESCO | District Electric Supply Company Ltd.\n",
      "DflD | Department for International Development, UK\n",
      "DP | Development Partner\n",
      "DRC | Democratic Republic of Congo\n",
      "E&M | Electrical an\n",
      "...\n"
     ]
    }
   ],
   "source": [
    "print(\"Sending abbreviations text to OpenAI API...\")\n",
    "print(f\"Input length: {len(abbreviations_text)} chars\")\n",
    "print()\n",
    "\n",
    "# Call custom GPT with prompt ID\n",
    "response = client.responses.create(\n",
    "    prompt={\n",
    "        \"id\": \"pmpt_69574fe1ff748195b16eca5fcc20d75202a70098695be261\",\n",
    "        \"version\": \"2\"\n",
    "    },\n",
    "    input=[\n",
    "        {\"role\": \"user\", \"content\": abbreviations_text}\n",
    "    ],\n",
    "    reasoning={\n",
    "        \"summary\": None\n",
    "    },\n",
    "    store=True,\n",
    "    include=[\n",
    "        \"reasoning.encrypted_content\",\n",
    "        \"web_search_call.action.sources\"\n",
    "    ]\n",
    ")\n",
    "\n",
    "# Extract the markdown table from the response\n",
    "for item in response.output:\n",
    "    if hasattr(item, 'content') and hasattr(item, 'role'):\n",
    "        abbr_table = item.content[0].text\n",
    "        break\n",
    "\n",
    "print(\"✓ Response received\")\n",
    "print(f\"  Response ID: {response.id}\")\n",
    "print(f\"  Status: {response.status}\")\n",
    "print(f\"  Table length: {len(abbr_table)} chars\")\n",
    "print(f\"\\nTable preview (first 500 chars):\")\n",
    "print(\"=\" * 80)\n",
    "print(abbr_table[:500])\n",
    "print(\"...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17012c12",
   "metadata": {},
   "source": [
    "### 8.03 Save Abbreviations Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6d4cce50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Saved abbreviations table to: /Users/lauren/repos/PAD2Skills/data/silver/abbreviations_md/P075941_abbr.md\n",
      "  File size: 4.40 KB\n"
     ]
    }
   ],
   "source": [
    "# Create output directory for abbreviations\n",
    "abbr_output_dir = project_root / \"data\" / \"silver\" / \"abbreviations_md\"\n",
    "abbr_output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "# Save abbreviations table\n",
    "abbr_output_file = abbr_output_dir / f\"{project_id}_abbr.md\"\n",
    "\n",
    "with open(abbr_output_file, 'w', encoding='utf-8') as f:\n",
    "    f.write(abbr_table)\n",
    "\n",
    "print(f\"✓ Saved abbreviations table to: {abbr_output_file}\")\n",
    "print(f\"  File size: {abbr_output_file.stat().st_size / 1024:.2f} KB\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAD2Skills",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
