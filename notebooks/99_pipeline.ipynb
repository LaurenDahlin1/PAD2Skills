{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7a587774",
   "metadata": {},
   "source": [
    "# Pipeline Runner\n",
    "\n",
    "Run utilities and pipeline steps for selected projects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f738d590",
   "metadata": {},
   "source": [
    "## 0. Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c2d3ae1",
   "metadata": {},
   "source": [
    "### 0.01 Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "542848c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "# Import our config\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.config import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11f4bc20",
   "metadata": {},
   "source": [
    "### 0.02 Load Configuration and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a04bcba3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment variables loaded\n",
      "  API Key: sk-proj-cj...__0A\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "project_root = Path.cwd().parent\n",
    "env_path = project_root / \".env\"\n",
    "\n",
    "if not env_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"'.env' file not found at {env_path}\\n\"\n",
    "        \"Please copy .env.example to .env and add your OpenAI API key.\"\n",
    "    )\n",
    "\n",
    "# Load from specific path\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Load project config\n",
    "config = load_config()\n",
    "\n",
    "# Get OpenAI API key from environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing required environment variable: OPENAI_API_KEY\")\n",
    "\n",
    "print(\"✓ Environment variables loaded\")\n",
    "print(f\"  API Key: {OPENAI_API_KEY[:10]}...{OPENAI_API_KEY[-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6f72ffc",
   "metadata": {},
   "source": [
    "### 0.03 Set Up Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c038ef4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Project data directory: /Users/lauren/repos/PAD2Skills/data/bronze/project_data\n",
      "All project details path: /Users/lauren/repos/PAD2Skills/data/bronze/project_data/all_project_details.csv\n",
      "Project summary path: /Users/lauren/repos/PAD2Skills/data/bronze/project_data/project_summary.csv\n",
      "Files exist: True / True\n"
     ]
    }
   ],
   "source": [
    "# Get paths\n",
    "project_data_dir = project_root / \"data\" / \"bronze\" / \"project_data\"\n",
    "all_project_details_path = project_data_dir / \"all_project_details.csv\"\n",
    "project_summary_path = project_data_dir / \"project_summary.csv\"\n",
    "\n",
    "print(f\"Project data directory: {project_data_dir}\")\n",
    "print(f\"All project details path: {all_project_details_path}\")\n",
    "print(f\"Project summary path: {project_summary_path}\")\n",
    "print(f\"Files exist: {all_project_details_path.exists()} / {project_summary_path.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a1428bc",
   "metadata": {},
   "source": [
    "## 1. Get Project Details"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18c2d9d6",
   "metadata": {},
   "source": [
    "### 1.01 Load Project Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "84307135",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All project details: 123 rows, 20 columns\n",
      "Project summary: 123 rows, 4 columns\n"
     ]
    }
   ],
   "source": [
    "# Read project details and summary\n",
    "all_project_details = pd.read_csv(all_project_details_path)\n",
    "project_summary = pd.read_csv(project_summary_path)\n",
    "\n",
    "print(f\"All project details: {all_project_details.shape[0]} rows, {all_project_details.shape[1]} columns\")\n",
    "print(f\"Project summary: {project_summary.shape[0]} rows, {project_summary.shape[1]} columns\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b97e31",
   "metadata": {},
   "source": [
    "### 1.02 Convert column names to snake_case"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b5a0bbd9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names after standardization:\n",
      "['project_id', 'status', 'team_leader', 'borrower_2', 'country', 'disclosure_date', 'approval_date', 'effective_date', 'total_project_cost_1', 'implementing_agency', 'region', 'fiscal_year_3', 'commitment_amount', 'environmental_category', 'environmental_and_social_risk', 'closing_date', 'last_stage_reached', 'last_update_date', 'consultant_services_required', 'associated_projects']\n"
     ]
    }
   ],
   "source": [
    "# Convert column names to snake_case\n",
    "all_project_details.columns = (\n",
    "    all_project_details.columns\n",
    "    .str.strip()\n",
    "    .str.lower()\n",
    "    .str.replace(' ', '_')\n",
    "    .str.replace(r'[^\\w]', '_', regex=True)\n",
    "    .str.replace(r'_+', '_', regex=True)\n",
    "    .str.strip('_')\n",
    ")\n",
    "\n",
    "print(\"Column names after standardization:\")\n",
    "print(list(all_project_details.columns))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "624b070f",
   "metadata": {},
   "source": [
    "### 1.03 Merge and Filter Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "0ebd1d42",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Merged data: 123 rows, 23 columns\n",
      "Projects with downloaded PADs: 98 rows\n",
      "\n",
      "First few projects:\n",
      "  project_id  status                                        team_leader  \\\n",
      "1    P119893  Closed                    Abdulhakim Mohammed Abdisubhan    \n",
      "3    P173506  Active  Didier Makoso Tsasa , Fabrice Karl Bertholet, ...   \n",
      "4    P176731  Active  Janina Franco , Abdulhakim Mohammed Abdisubhan...   \n",
      "5    P507759  Active                     Jenny Jing Chao , Maria Arango   \n",
      "6    P180547  Active   Monali Ranade , Dana Rysankova, Alona Kazantseva   \n",
      "\n",
      "                                          borrower_2  \\\n",
      "1            Federal Democratic Republic of Ethiopia   \n",
      "3                       DEMOCRATIC REPUBLIC OF CONGO   \n",
      "4            Federal Democratic Republic of Ethiopia   \n",
      "5                             Republic of Mozambique   \n",
      "6  Common Market for Eastern and Southern Africa ...   \n",
      "\n",
      "                         country    disclosure_date  \\\n",
      "1                       Ethiopia  December 22, 2011   \n",
      "3  Congo, Democratic Republic of    January 6, 2021   \n",
      "4                       Ethiopia    August 15, 2023   \n",
      "5                     Mozambique  November 29, 2024   \n",
      "6    Eastern and Southern Africa       July 7, 2023   \n",
      "\n",
      "                approval_date   effective_date  total_project_cost_1  \\\n",
      "1  (as of board presentation)  January 4, 2013    US$ 275.00 million   \n",
      "3  (as of board presentation)     May 18, 2023    US$ 939.00 million   \n",
      "4  (as of board presentation)    June 19, 2024    US$ 537.00 million   \n",
      "5  (as of board presentation)  August 21, 2025      US$ 0.00 million   \n",
      "6  (as of board presentation)    April 5, 2024  US$ 10000.00 million   \n",
      "\n",
      "                                 implementing_agency  ...  \\\n",
      "1  Development Bank of Ethiopia,Ethiopia Electric...  ...   \n",
      "3  Ministère des Ressources Hydrauliques et de l'...  ...   \n",
      "4  Ethiopia Electric Power,Ethiopia Electric Utility  ...   \n",
      "5  Electricidade de Moçambique (EDM),Fundo de Ene...  ...   \n",
      "6  Common Market for Eastern and Southern Africa ...  ...   \n",
      "\n",
      "  environmental_category  environmental_and_social_risk        closing_date  \\\n",
      "1                      B                 Not Applicable      March 31, 2025   \n",
      "3                    NaN                           High  September 30, 2029   \n",
      "4                    NaN                           High     August 30, 2030   \n",
      "5                    NaN                    Substantial   December 31, 2030   \n",
      "6                    NaN                    Substantial   December 31, 2030   \n",
      "\n",
      "  last_stage_reached last_update_date consultant_services_required  \\\n",
      "1      Bank Approved    June 20, 2024                           No   \n",
      "3      Bank Approved    June 17, 2024                          Yes   \n",
      "4      Bank Approved    June 16, 2023                           No   \n",
      "5      Bank Approved   March 22, 2025                          TBD   \n",
      "6      Bank Approved    July 16, 2023                          Yes   \n",
      "\n",
      "  associated_projects details_found pads_found pads_downloaded  \n",
      "1             P155563             1          1               1  \n",
      "3                 NaN             1          1               1  \n",
      "4                 NaN             1          1               1  \n",
      "5             P512418             1          1               1  \n",
      "6                 NaN             1          1               1  \n",
      "\n",
      "[5 rows x 23 columns]\n"
     ]
    }
   ],
   "source": [
    "# Merge project_summary to all_project_details\n",
    "all_projects = all_project_details.merge(\n",
    "    project_summary,\n",
    "    on=\"project_id\",\n",
    "    how=\"left\"\n",
    ")\n",
    "\n",
    "print(f\"Merged data: {all_projects.shape[0]} rows, {all_projects.shape[1]} columns\")\n",
    "\n",
    "# Keep only projects with downloaded PADs\n",
    "all_projects = all_projects[all_projects[\"pads_downloaded\"] >= 1]\n",
    "\n",
    "print(f\"Projects with downloaded PADs: {all_projects.shape[0]} rows\")\n",
    "print(f\"\\nFirst few projects:\")\n",
    "print(all_projects.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ae8c430",
   "metadata": {},
   "source": [
    "## 2. Select Projects"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4ea7d163",
   "metadata": {},
   "source": [
    "### 2.01 Select first 10 Projects or define your own list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "74e4038e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected 10 projects:\n",
      "  P119893\n",
      "  P173506\n",
      "  P176731\n",
      "  P507759\n",
      "  P180547\n",
      "  P505856\n",
      "  P181341\n",
      "  P075941\n",
      "  P160708\n",
      "  P153743\n"
     ]
    }
   ],
   "source": [
    "# Select first 10 project IDs\n",
    "selected_projects = all_projects.head(10)[\"project_id\"].tolist()\n",
    "\n",
    "print(f\"Selected {len(selected_projects)} projects:\")\n",
    "for project_id in selected_projects:\n",
    "    print(f\"  {project_id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "83fa2704",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom list (first 10 plus important project)\n",
    "selected_projects = ['P119893', 'P173506', 'P176731', 'P507759', \n",
    "                     'P180547', 'P505856', 'P181341', 'P075941', 'P160708', \n",
    "                     'P153743', 'P511453']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae6197bb",
   "metadata": {},
   "source": [
    "### 2.02 Filter Projects DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "28fe40dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered to 11 projects:\n",
      "project_id status                       country\n",
      "   P119893 Closed                      Ethiopia\n",
      "   P173506 Active Congo, Democratic Republic of\n",
      "   P176731 Active                      Ethiopia\n",
      "   P507759 Active                    Mozambique\n",
      "   P180547 Active   Eastern and Southern Africa\n",
      "   P505856 Active                    Seychelles\n",
      "   P181341 Active  Somalia, Federal Republic of\n",
      "   P075941 Closed   Eastern and Southern Africa\n",
      "   P160708 Active    Western and Central Africa\n",
      "   P153743 Closed                         Niger\n",
      "   P511453 Active                        Guinea\n"
     ]
    }
   ],
   "source": [
    "# Filter projects dataframe for selected projects\n",
    "projects_df = all_projects[all_projects[\"project_id\"].isin(selected_projects)]\n",
    "\n",
    "print(f\"Filtered to {len(projects_df)} projects:\")\n",
    "print(projects_df[[\"project_id\", \"status\", \"country\"]].to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593a1046",
   "metadata": {},
   "source": [
    "### 2.03 Save Selected Projects Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "6ff39ba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved 11 projects to:\n",
      "  /Users/lauren/repos/PAD2Skills/data/silver/selected_projects_data/selected_projects.csv\n"
     ]
    }
   ],
   "source": [
    "# Save filtered projects to silver directory\n",
    "output_dir = project_root / \"data\" / \"silver\" / \"selected_projects_data\"\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "output_path = output_dir / \"selected_projects.csv\"\n",
    "projects_df.to_csv(output_path, index=False)\n",
    "\n",
    "print(f\"Saved {len(projects_df)} projects to:\")\n",
    "print(f\"  {output_path}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51a372be",
   "metadata": {},
   "source": [
    "## 3. Convert PDFs to Markdown"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cef817c7",
   "metadata": {},
   "source": [
    "### 3.01 Import PDF Conversion Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f3988830",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/lauren/repos/PAD2Skills/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ PDF conversion module imported\n"
     ]
    }
   ],
   "source": [
    "from src.pdf_conversion.converter import convert_pdfs\n",
    "\n",
    "print(\"✓ PDF conversion module imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c51c9288",
   "metadata": {},
   "source": [
    "### 3.02 Set Up PDF Conversion Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "1e74ee0e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PDF directory: /Users/lauren/repos/PAD2Skills/data/bronze/pads_pdf\n",
      "Markdown directory: /Users/lauren/repos/PAD2Skills/data/silver/pads_md\n",
      "PDF directory exists: True\n"
     ]
    }
   ],
   "source": [
    "# Set up paths for PDF conversion\n",
    "pdf_dir = project_root / config.paths.raw_pdfs\n",
    "markdown_dir = project_root / config.paths.markdown\n",
    "\n",
    "print(f\"PDF directory: {pdf_dir}\")\n",
    "print(f\"Markdown directory: {markdown_dir}\")\n",
    "print(f\"PDF directory exists: {pdf_dir.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5f714f",
   "metadata": {},
   "source": [
    "### 3.03 Convert PDFs for Selected Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "6a06639e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "○ Skipped (already exists): P119893\n",
      "○ Skipped (already exists): P173506\n",
      "○ Skipped (already exists): P176731\n",
      "○ Skipped (already exists): P507759\n",
      "○ Skipped (already exists): P180547\n",
      "○ Skipped (already exists): P505856\n",
      "○ Skipped (already exists): P181341\n",
      "○ Skipped (already exists): P075941\n",
      "○ Skipped (already exists): P160708\n",
      "○ Skipped (already exists): P153743\n",
      "○ Skipped (already exists): P511453\n"
     ]
    }
   ],
   "source": [
    "# Convert PDFs for each selected project\n",
    "for project_id in selected_projects:\n",
    "    pdf_file = pdf_dir / f\"{project_id}_1.pdf\"\n",
    "    \n",
    "    # Skip if PDF doesn't exist\n",
    "    if not pdf_file.exists():\n",
    "        print(f\"⚠ PDF not found: {project_id}\")\n",
    "        continue\n",
    "    \n",
    "    # Convert single PDF using the src utility\n",
    "    results = convert_pdfs(\n",
    "        pdf_dir=pdf_dir,\n",
    "        output_dir=markdown_dir,\n",
    "        specific_pdf=pdf_file.name,\n",
    "        overwrite=False,\n",
    "        accurate_tables=True\n",
    "    )\n",
    "    \n",
    "    # Report result\n",
    "    if results[\"converted\"]:\n",
    "        print(f\"✓ Converted: {project_id}\")\n",
    "    elif results[\"skipped\"]:\n",
    "        print(f\"○ Skipped (already exists): {project_id}\")\n",
    "    elif results[\"failed\"]:\n",
    "        error = results[\"failed\"][0][1]\n",
    "        print(f\"✗ Failed: {project_id} - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efbdd056",
   "metadata": {},
   "source": [
    "## 4. Extract Document Sections"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5c6a7f1",
   "metadata": {},
   "source": [
    "### 4.01 Import Section Extraction Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d84ff31e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Section extraction module imported\n"
     ]
    }
   ],
   "source": [
    "from src.extraction.extractor import extract_all_sections\n",
    "\n",
    "print(\"✓ Section extraction module imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd158a4f",
   "metadata": {},
   "source": [
    "### 4.02 Set Up Section Extraction Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "52ab07e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown directory: /Users/lauren/repos/PAD2Skills/data/silver/pads_md\n",
      "Sections output directory: /Users/lauren/repos/PAD2Skills/data/silver/document_sections\n"
     ]
    }
   ],
   "source": [
    "# Set up paths for section extraction\n",
    "sections_output_dir = project_root / \"data\" / \"silver\" / \"document_sections\"\n",
    "\n",
    "print(f\"Markdown directory: {markdown_dir}\")\n",
    "print(f\"Sections output directory: {sections_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c49ea40e",
   "metadata": {},
   "source": [
    "### 4.03 Extract Sections for Selected Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9081bc90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "○ Skipped (already exists): P119893\n",
      "○ Skipped (already exists): P173506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:52:03,376 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted sections: P176731\n",
      "○ Skipped (already exists): P507759\n",
      "○ Skipped (already exists): P180547\n",
      "○ Skipped (already exists): P505856\n",
      "○ Skipped (already exists): P181341\n",
      "○ Skipped (already exists): P075941\n",
      "○ Skipped (already exists): P160708\n",
      "○ Skipped (already exists): P153743\n",
      "○ Skipped (already exists): P511453\n"
     ]
    }
   ],
   "source": [
    "# Extract sections for each selected project\n",
    "for project_id in selected_projects:\n",
    "    md_file = markdown_dir / f\"{project_id}_1.md\"\n",
    "    \n",
    "    # Skip if markdown doesn't exist\n",
    "    if not md_file.exists():\n",
    "        print(f\"⚠ Markdown not found: {project_id}\")\n",
    "        continue\n",
    "    \n",
    "    # Extract sections using the src utility\n",
    "    results = extract_all_sections(\n",
    "        markdown_dir=markdown_dir,\n",
    "        output_dir=sections_output_dir,\n",
    "        specific_file=md_file.name,\n",
    "        overwrite=False\n",
    "    )\n",
    "    \n",
    "    # Report result\n",
    "    if results[\"extracted\"]:\n",
    "        print(f\"✓ Extracted sections: {project_id}\")\n",
    "    elif results[\"skipped\"]:\n",
    "        print(f\"○ Skipped (already exists): {project_id}\")\n",
    "    elif results[\"failed\"]:\n",
    "        error = results[\"failed\"][0][1]\n",
    "        print(f\"✗ Failed: {project_id} - {error}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ced715e",
   "metadata": {},
   "source": [
    "## 5. Extract Abbreviations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c46fa3d2",
   "metadata": {},
   "source": [
    "### 5.01 Import Abbreviation Extraction Module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a0a529ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Abbreviation extraction module imported\n"
     ]
    }
   ],
   "source": [
    "from src.extraction.extractor import extract_all_abbreviations\n",
    "\n",
    "print(\"✓ Abbreviation extraction module imported\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be10e1ff",
   "metadata": {},
   "source": [
    "### 5.02 Set Up Abbreviation Extraction Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e09f0edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markdown directory: /Users/lauren/repos/PAD2Skills/data/silver/pads_md\n",
      "Abbreviations output directory: /Users/lauren/repos/PAD2Skills/data/silver/abbreviations_md\n"
     ]
    }
   ],
   "source": [
    "# Set up paths for abbreviation extraction\n",
    "abbreviations_output_dir = project_root / \"data\" / \"silver\" / \"abbreviations_md\"\n",
    "\n",
    "print(f\"Markdown directory: {markdown_dir}\")\n",
    "print(f\"Abbreviations output directory: {abbreviations_output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26c6d545",
   "metadata": {},
   "source": [
    "### 5.03 Extract Abbreviations for Selected Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "45225a3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:52:43,157 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted abbreviations: P119893\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:53:24,731 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted abbreviations: P173506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:53:46,955 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted abbreviations: P176731\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:54:21,001 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted abbreviations: P507759\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:55:06,728 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted abbreviations: P180547\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:55:17,786 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted abbreviations: P505856\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:56:00,093 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted abbreviations: P181341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:56:25,306 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 502 Bad Gateway\"\n",
      "2026-01-02 17:56:25,308 - INFO - Retrying request to /responses in 0.449558 seconds\n",
      "2026-01-02 17:57:27,568 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted abbreviations: P075941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:58:15,495 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted abbreviations: P160708\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:58:49,697 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted abbreviations: P153743\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2026-01-02 17:59:42,334 - INFO - HTTP Request: POST https://api.openai.com/v1/responses \"HTTP/1.1 200 OK\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Extracted abbreviations: P511453\n"
     ]
    }
   ],
   "source": [
    "# Extract abbreviations for each selected project\n",
    "for project_id in selected_projects:\n",
    "    md_file = markdown_dir / f\"{project_id}_1.md\"\n",
    "    \n",
    "    # Skip if markdown doesn't exist\n",
    "    if not md_file.exists():\n",
    "        print(f\"⚠ Markdown not found: {project_id}\")\n",
    "        continue\n",
    "    \n",
    "    # Extract abbreviations using the src utility\n",
    "    results = extract_all_abbreviations(\n",
    "        markdown_dir=markdown_dir,\n",
    "        output_dir=abbreviations_output_dir,\n",
    "        specific_file=md_file.name,\n",
    "        overwrite=False\n",
    "    )\n",
    "    \n",
    "    # Report result\n",
    "    if results[\"extracted\"]:\n",
    "        print(f\"✓ Extracted abbreviations: {project_id}\")\n",
    "    elif results[\"skipped\"]:\n",
    "        print(f\"○ Skipped (already exists): {project_id}\")\n",
    "    elif results[\"failed\"]:\n",
    "        error = results[\"failed\"][0][1]\n",
    "        print(f\"✗ Failed: {project_id} - {error}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAD2Skills",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
