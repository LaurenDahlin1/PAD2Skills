{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34bb6847",
   "metadata": {},
   "source": [
    "# Extract Occupations and Skills from PAD Chunks\n",
    "\n",
    "Extract occupations and skills from markdown chunks using OpenAI custom GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0438565",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d5fc2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Import our config\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.config import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656b3a0",
   "metadata": {},
   "source": [
    "## 2. Load Configuration and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0a626195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Environment variables loaded\n",
      "  API Key: sk-proj-cj...__0A\n"
     ]
    }
   ],
   "source": [
    "# Load environment variables from .env file\n",
    "project_root = Path.cwd().parent\n",
    "env_path = project_root / \".env\"\n",
    "\n",
    "if not env_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"'.env' file not found at {env_path}\\n\"\n",
    "        \"Please copy .env.example to .env and add your OpenAI API key.\"\n",
    "    )\n",
    "\n",
    "# Load from specific path\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Load project config\n",
    "config = load_config()\n",
    "\n",
    "# Get OpenAI API key from environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing required environment variable: OPENAI_API_KEY\")\n",
    "\n",
    "print(\"✓ Environment variables loaded\")\n",
    "print(f\"  API Key: {OPENAI_API_KEY[:10]}...{OPENAI_API_KEY[-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc91d3d",
   "metadata": {},
   "source": [
    "## 3. Set Up Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9a619860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunks directory: /Users/lauren/repos/PAD2Skills/data/silver/pads_md_chunks\n",
      "Output directory: /Users/lauren/repos/PAD2Skills/data/silver/occupations_skills_json\n",
      "Chunks exist: True\n"
     ]
    }
   ],
   "source": [
    "# Get paths\n",
    "md_dir = project_root / config.paths.markdown\n",
    "chunks_dir = md_dir.parent / \"pads_md_chunks\"\n",
    "output_dir = project_root / \"data\" / \"silver\" / \"occupations_skills_json\"\n",
    "\n",
    "# Create output directory\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Chunks directory: {chunks_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Chunks exist: {chunks_dir.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158bd4da",
   "metadata": {},
   "source": [
    "## 4. Load Chunk Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "20acf53d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 16 chunk files\n",
      "\n",
      "First 5 chunks:\n",
      "  P075941_0_strategic_context.md                                30.30 KB\n",
      "  P075941_10_economic_and_financial_analysis_implementation_arrangements.md 185.08 KB\n",
      "  P075941_11_power_supply_options_for_the_nile_equatorial_lakes_region_nel.md  10.44 KB\n",
      "  P075941_12_summary_of_the_power_sectors_in_burundi_rwanda_and_tanzania.md  32.54 KB\n",
      "  P075941_13_implementation_support_team.md                      5.18 KB\n",
      "  ... and 11 more\n"
     ]
    }
   ],
   "source": [
    "# Find all markdown chunk files\n",
    "chunk_files = sorted(chunks_dir.glob(\"*.md\"))\n",
    "\n",
    "print(f\"Found {len(chunk_files)} chunk files\")\n",
    "print(\"\\nFirst 5 chunks:\")\n",
    "for chunk_file in chunk_files[:5]:\n",
    "    size_kb = chunk_file.stat().st_size / 1024\n",
    "    print(f\"  {chunk_file.name:60s} {size_kb:6.2f} KB\")\n",
    "\n",
    "if len(chunk_files) > 5:\n",
    "    print(f\"  ... and {len(chunk_files) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef26157",
   "metadata": {},
   "source": [
    "## 5. Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "179a7b9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ OpenAI client initialized\n"
     ]
    }
   ],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"✓ OpenAI client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545e4e7",
   "metadata": {},
   "source": [
    "## 6. Process Each Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2847ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing 16 chunks...\n",
      "\n",
      "[1/16] Processing: P075941_0_strategic_context.md\n",
      "  Project ID: P075941, Section ID: 0\n",
      "  Chunk size: 31030 chars\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'null' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[12]\u001b[39m\u001b[32m, line 32\u001b[39m\n\u001b[32m     20\u001b[39m input_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mproject_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mproject_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33msection_id: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00msection_id\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33mchunk_text: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mchunk_text\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     22\u001b[39m \u001b[38;5;66;03m# Call custom GPT with prompt ID\u001b[39;00m\n\u001b[32m     23\u001b[39m response = client.responses.create(\n\u001b[32m     24\u001b[39m     prompt={\n\u001b[32m     25\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mid\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33mpmpt_6950c224bab0819486a7f38e0ae0109b08192593c3d4b4af\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     26\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mversion\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33m13\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     27\u001b[39m     },\n\u001b[32m     28\u001b[39m     \u001b[38;5;28minput\u001b[39m=[\n\u001b[32m     29\u001b[39m         {\u001b[33m\"\u001b[39m\u001b[33mrole\u001b[39m\u001b[33m\"\u001b[39m: \u001b[33m\"\u001b[39m\u001b[33muser\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33mcontent\u001b[39m\u001b[33m\"\u001b[39m: input_message}\n\u001b[32m     30\u001b[39m     ],\n\u001b[32m     31\u001b[39m     reasoning={\n\u001b[32m---> \u001b[39m\u001b[32m32\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33msummary\u001b[39m\u001b[33m\"\u001b[39m: \u001b[43mnull\u001b[49m\n\u001b[32m     33\u001b[39m     },\n\u001b[32m     34\u001b[39m     store=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     35\u001b[39m     include=[\n\u001b[32m     36\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mreasoning.encrypted_content\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m     37\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mweb_search_call.action.sources\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     38\u001b[39m     ]\n\u001b[32m     39\u001b[39m )\n\u001b[32m     41\u001b[39m \u001b[38;5;66;03m# Extract the text from the response\u001b[39;00m\n\u001b[32m     42\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'null' is not defined"
     ]
    }
   ],
   "source": [
    "print(f\"Processing {len(chunk_files)} chunks...\")\n",
    "print()\n",
    "\n",
    "processed_chunks = []\n",
    "\n",
    "for i, chunk_file in enumerate(chunk_files, 1):\n",
    "    # Parse filename: {project_id}_{section_id}_{snake_title}.md\n",
    "    filename_parts = chunk_file.stem.split('_', 2)\n",
    "    project_id = filename_parts[0]\n",
    "    section_id = filename_parts[1]\n",
    "    \n",
    "    # Read chunk content\n",
    "    chunk_text = chunk_file.read_text(encoding='utf-8')\n",
    "    \n",
    "    print(f\"[{i}/{len(chunk_files)}] Processing: {chunk_file.name}\")\n",
    "    print(f\"  Project ID: {project_id}, Section ID: {section_id}\")\n",
    "    print(f\"  Chunk size: {len(chunk_text)} chars\")\n",
    "    \n",
    "    # Prepare input for custom GPT\n",
    "    input_message = f\"project_id: {project_id}\\nsection_id: {section_id}\\nchunk_text: {chunk_text}\"\n",
    "    \n",
    "    # Call custom GPT with prompt ID\n",
    "    response = client.responses.create(\n",
    "        prompt={\n",
    "            \"id\": \"pmpt_6950c224bab0819486a7f38e0ae0109b08192593c3d4b4af\",\n",
    "            \"version\": \"13\"\n",
    "        },\n",
    "        input=[\n",
    "            {\"role\": \"user\", \"content\": input_message}\n",
    "        ],\n",
    "        reasoning={\n",
    "            \"summary\": None\n",
    "        },\n",
    "        store=False,\n",
    "        include=[\n",
    "            \"reasoning.encrypted_content\",\n",
    "            \"web_search_call.action.sources\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Extract the text from the response\n",
    "    result = None\n",
    "    for item in response.output:\n",
    "        if hasattr(item, 'content') and hasattr(item, 'role'):\n",
    "            result = item.content[0].text\n",
    "            break\n",
    "    \n",
    "    # Save result to file\n",
    "    output_file = output_dir / f\"{project_id}_{section_id}_occupations.json\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(result)\n",
    "    \n",
    "    processed_chunks.append({\n",
    "        'chunk_file': chunk_file.name,\n",
    "        'project_id': project_id,\n",
    "        'section_id': section_id,\n",
    "        'output_file': output_file.name,\n",
    "        'response_id': response.id\n",
    "    })\n",
    "    \n",
    "    print(f\"  ✓ Saved to: {output_file.name}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"✓ Processed {len(processed_chunks)} chunks\")\n",
    "print(f\"✓ Results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b6e20",
   "metadata": {},
   "source": [
    "## 7. Verify Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07276056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all output files\n",
    "output_files = sorted(output_dir.glob(\"*_occupations.json\"))\n",
    "\n",
    "print(f\"Created {len(output_files)} output files:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for output_file in output_files[:10]:  # Show first 10\n",
    "    size_kb = output_file.stat().st_size / 1024\n",
    "    print(f\"  {output_file.name:60s} {size_kb:6.2f} KB\")\n",
    "\n",
    "if len(output_files) > 10:\n",
    "    print(f\"  ... and {len(output_files) - 10} more\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total output files: {len(output_files)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PAD2Skills",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
