{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "34bb6847",
   "metadata": {},
   "source": [
    "# Extract Occupations and Skills from PAD Chunks\n",
    "\n",
    "Extract occupations and skills from markdown chunks using OpenAI custom GPT."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0438565",
   "metadata": {},
   "source": [
    "## 1. Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5fc2bbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pathlib import Path\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "from openai import OpenAI\n",
    "\n",
    "# Import our config\n",
    "import sys\n",
    "sys.path.append(str(Path.cwd().parent))\n",
    "from src.config import load_config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9656b3a0",
   "metadata": {},
   "source": [
    "## 2. Load Configuration and Environment Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a626195",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load environment variables from .env file\n",
    "project_root = Path.cwd().parent\n",
    "env_path = project_root / \".env\"\n",
    "\n",
    "if not env_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"'.env' file not found at {env_path}\\n\"\n",
    "        \"Please copy .env.example to .env and add your OpenAI API key.\"\n",
    "    )\n",
    "\n",
    "# Load from specific path\n",
    "load_dotenv(env_path, override=True)\n",
    "\n",
    "# Load project config\n",
    "config = load_config()\n",
    "\n",
    "# Get OpenAI API key from environment\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "# Verify API key is set\n",
    "if not OPENAI_API_KEY:\n",
    "    raise ValueError(\"Missing required environment variable: OPENAI_API_KEY\")\n",
    "\n",
    "print(\"✓ Environment variables loaded\")\n",
    "print(f\"  API Key: {OPENAI_API_KEY[:10]}...{OPENAI_API_KEY[-4:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dbc91d3d",
   "metadata": {},
   "source": [
    "## 3. Set Up Paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a619860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get paths\n",
    "md_dir = project_root / config.paths.markdown\n",
    "chunks_dir = md_dir.parent / \"pads_md_chunks\"\n",
    "output_dir = project_root / \"data\" / \"silver\" / \"occupations_skills\"\n",
    "\n",
    "# Create output directory\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(f\"Chunks directory: {chunks_dir}\")\n",
    "print(f\"Output directory: {output_dir}\")\n",
    "print(f\"Chunks exist: {chunks_dir.exists()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158bd4da",
   "metadata": {},
   "source": [
    "## 4. Load Chunk Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20acf53d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all markdown chunk files\n",
    "chunk_files = sorted(chunks_dir.glob(\"*.md\"))\n",
    "\n",
    "print(f\"Found {len(chunk_files)} chunk files\")\n",
    "print(\"\\nFirst 5 chunks:\")\n",
    "for chunk_file in chunk_files[:5]:\n",
    "    size_kb = chunk_file.stat().st_size / 1024\n",
    "    print(f\"  {chunk_file.name:60s} {size_kb:6.2f} KB\")\n",
    "\n",
    "if len(chunk_files) > 5:\n",
    "    print(f\"  ... and {len(chunk_files) - 5} more\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef26157",
   "metadata": {},
   "source": [
    "## 5. Initialize OpenAI Client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "179a7b9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "print(\"✓ OpenAI client initialized\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9545e4e7",
   "metadata": {},
   "source": [
    "## 6. Process Each Chunk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2847ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Processing {len(chunk_files)} chunks...\")\n",
    "print()\n",
    "\n",
    "processed_chunks = []\n",
    "\n",
    "for i, chunk_file in enumerate(chunk_files, 1):\n",
    "    # Parse filename: {project_id}_{section_id}_{snake_title}.md\n",
    "    filename_parts = chunk_file.stem.split('_', 2)\n",
    "    project_id = filename_parts[0]\n",
    "    section_id = filename_parts[1]\n",
    "    \n",
    "    # Read chunk content\n",
    "    chunk_text = chunk_file.read_text(encoding='utf-8')\n",
    "    \n",
    "    print(f\"[{i}/{len(chunk_files)}] Processing: {chunk_file.name}\")\n",
    "    print(f\"  Project ID: {project_id}, Section ID: {section_id}\")\n",
    "    print(f\"  Chunk size: {len(chunk_text)} chars\")\n",
    "    \n",
    "    # Prepare input for custom GPT\n",
    "    input_message = f\"project_id: {project_id}\\nsection_id: {section_id}\\nchunk_text: {chunk_text}\"\n",
    "    \n",
    "    # Call custom GPT with prompt ID\n",
    "    response = client.responses.create(\n",
    "        prompt={\n",
    "            \"id\": \"pmpt_6950c224bab0819486a7f38e0ae0109b08192593c3d4b4af\",\n",
    "            \"version\": \"10\"\n",
    "        },\n",
    "        input=[\n",
    "            {\"role\": \"user\", \"content\": input_message}\n",
    "        ],\n",
    "        reasoning={\n",
    "            \"summary\": \"auto\"\n",
    "        },\n",
    "        store=True,\n",
    "        include=[\n",
    "            \"reasoning.encrypted_content\",\n",
    "            \"web_search_call.action.sources\"\n",
    "        ]\n",
    "    )\n",
    "    \n",
    "    # Extract the text from the response\n",
    "    result = None\n",
    "    for item in response.output:\n",
    "        if hasattr(item, 'content') and hasattr(item, 'role'):\n",
    "            result = item.content[0].text\n",
    "            break\n",
    "    \n",
    "    # Save result to file\n",
    "    output_file = output_dir / f\"{project_id}_{section_id}_occupations.json\"\n",
    "    with open(output_file, 'w', encoding='utf-8') as f:\n",
    "        f.write(result)\n",
    "    \n",
    "    processed_chunks.append({\n",
    "        'chunk_file': chunk_file.name,\n",
    "        'project_id': project_id,\n",
    "        'section_id': section_id,\n",
    "        'output_file': output_file.name,\n",
    "        'response_id': response.id\n",
    "    })\n",
    "    \n",
    "    print(f\"  ✓ Saved to: {output_file.name}\")\n",
    "    print()\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"✓ Processed {len(processed_chunks)} chunks\")\n",
    "print(f\"✓ Results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "782b6e20",
   "metadata": {},
   "source": [
    "## 7. Verify Output Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07276056",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List all output files\n",
    "output_files = sorted(output_dir.glob(\"*_occupations.json\"))\n",
    "\n",
    "print(f\"Created {len(output_files)} output files:\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "for output_file in output_files[:10]:  # Show first 10\n",
    "    size_kb = output_file.stat().st_size / 1024\n",
    "    print(f\"  {output_file.name:60s} {size_kb:6.2f} KB\")\n",
    "\n",
    "if len(output_files) > 10:\n",
    "    print(f\"  ... and {len(output_files) - 10} more\")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(f\"Total output files: {len(output_files)}\")"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
